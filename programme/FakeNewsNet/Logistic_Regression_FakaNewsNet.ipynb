{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOOUHTMP02oES7rzFq8IO8F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ybUmMcQdBLLT","executionInfo":{"status":"ok","timestamp":1764511056183,"user_tz":-420,"elapsed":9148,"user":{"displayName":"ngo cong","userId":"09373141506726908581"}},"outputId":"67631858-86ea-4cec-bbb7-a5474a8f51d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚è≥ ƒêang t·∫£i dataset FakeNewsNet...\n","‚ö†Ô∏è T·∫£i config con th·∫•t b·∫°i (BuilderConfig 'gossipcop' not found. Available: ['default']), t·∫£i b·∫£n default...\n","Dataset columns: ['title', 'news_url', 'source_domain', 'tweet_num', 'real']\n","T·ªïng s·ªë m·∫´u d·ªØ li·ªáu: 23196\n","‚úÖ ƒê√£ nh·∫≠n di·ªán c·ªôt: Text='None', Title='title', Label='real'\n","üßπ Pre-processing...\n"," ‚Üí Sau x·ª≠ l√Ω: 22,355\n","Train: 17884 | Test: 4471\n","\n","‚öôÔ∏è Vectorizing (TF-IDF)...\n","üöÄ Training SVM (LinearSVC)...\n","\n","üéØ ƒêANG ƒê√ÅNH GI√Å (TEST SET)...\n","\n","==================================================\n","üìä K·∫æT QU·∫¢ SVM BASELINE - FAKENEWSNET:\n","==================================================\n","{'eval_accuracy': 0.842764482218743, 'eval_precision': 0.8377817144742215, 'eval_recall': 0.842764482218743, 'eval_f1': 0.8394047671549866, 'eval_auc': np.float64(0.8728297058691242), 'eval_loss': 'N/A (SVM)', 'eval_runtime': 0.021673917770385742, 'eval_samples_per_second': 206284.80957462022, 'eval_steps_per_second': 'N/A'}\n","==================================================\n","\n","‚úÖ ƒê√£ l∆∞u model t·∫°i: /content/drive/MyDrive/FakeNewsNet_SVM_Baseline\n"]}],"source":["# =====================================================\n","# BASELINE: SVM (LinearSVC) - FAKENEWSNET\n","# Output Format: HuggingFace Style\n","# =====================================================\n","\n","import os, re, psutil, pickle, time\n","import pandas as pd\n","import numpy as np\n","from datasets import load_dataset, concatenate_datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.svm import LinearSVC\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n","from google.colab import drive\n","\n","# 1. MOUNT DRIVE\n","if not os.path.exists('/content/drive'):\n","    try:\n","        drive.mount('/content/drive', force_remount=True)\n","    except ValueError: pass\n","\n","OUTPUT_DIR = \"/content/drive/MyDrive/FakeNewsNet_SVM_Baseline\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# 2. LOAD DATA (G·ªôp GossipCop + PolitiFact)\n","print(\"‚è≥ ƒêang t·∫£i dataset FakeNewsNet...\")\n","try:\n","    # C·ªë g·∫Øng t·∫£i 2 t·∫≠p con\n","    ds_gossip = load_dataset(\"rickstello/FakeNewsNet\", \"gossipcop\", split=\"train\")\n","    ds_politi = load_dataset(\"rickstello/FakeNewsNet\", \"politifact\", split=\"train\")\n","    dataset_full = concatenate_datasets([ds_gossip, ds_politi])\n","    df = pd.DataFrame(dataset_full)\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è T·∫£i config con th·∫•t b·∫°i ({e}), t·∫£i b·∫£n default...\")\n","    dataset = load_dataset(\"rickstello/FakeNewsNet\", split=\"train\")\n","    df = pd.DataFrame(dataset)\n","\n","print(f\"Dataset columns: {df.columns.tolist()}\") # In ra ƒë·ªÉ ki·ªÉm tra\n","print(f\"T·ªïng s·ªë m·∫´u d·ªØ li·ªáu: {len(df)}\")\n","\n","# 3. PRE-PROCESSING (FIX L·ªñI KEYERROR)\n","\n","# A. T√¨m t√™n c·ªôt an to√†n\n","# ∆Øu ti√™n c√°c t√™n c·ªôt th∆∞·ªùng g·∫∑p\n","text_col = next((c for c in ['news_content', 'text', 'content', 'body'] if c in df.columns), None)\n","title_col = next((c for c in ['title', 'news_title', 'headline'] if c in df.columns), None)\n","label_col = next((c for c in ['real', 'label', 'class', 'fake'] if c in df.columns), None)\n","\n","if not label_col:\n","    raise ValueError(f\"‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt nh√£n! C√°c c·ªôt hi·ªán c√≥: {df.columns.tolist()}\")\n","\n","print(f\"‚úÖ ƒê√£ nh·∫≠n di·ªán c·ªôt: Text='{text_col}', Title='{title_col}', Label='{label_col}'\")\n","\n","# B. X·ª≠ l√Ω d·ªØ li·ªáu\n","# X·ª≠ l√Ω an to√†n: N·∫øu kh√¥ng t√¨m th·∫•y c·ªôt Text/Title th√¨ d√πng chu·ªói r·ªóng thay v√¨ crash\n","text_data = df[text_col].fillna('') if text_col else pd.Series([\"\"] * len(df))\n","title_data = df[title_col].fillna('') if title_col else pd.Series([\"\"] * len(df))\n","\n","# Chu·∫©n h√≥a Label\n","df['label'] = df[label_col].astype(int)\n","\n","# C. Clean Text\n","def clean_text_ml(s):\n","    if not isinstance(s, str): return \"\"\n","    s = s.lower()\n","    s = re.sub(r'https?://\\S+', '', s)\n","    s = re.sub(r'<.*?>', '', s)\n","    s = re.sub(r'[^a-z0-9\\s]', '', s)\n","    s = re.sub(r'\\s+', ' ', s).strip()\n","    return s\n","\n","print(\"üßπ Pre-processing...\")\n","# Gh√©p Title + Text\n","df['content'] = (title_data + \" \" + text_data).apply(clean_text_ml)\n","\n","# L·ªçc b·ªè m·∫´u qu√° ng·∫Øn\n","df = df[df['content'].str.len() > 20]\n","print(f\" ‚Üí Sau x·ª≠ l√Ω: {len(df):,}\")\n","\n","# 4. SPLIT DATA\n","X_train_text, X_test_text, y_train, y_test = train_test_split(\n","    df['content'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",")\n","\n","print(f\"Train: {len(X_train_text)} | Test: {len(X_test_text)}\")\n","\n","# 5. TF-IDF VECTORIZATION\n","print(\"\\n‚öôÔ∏è Vectorizing (TF-IDF)...\")\n","vectorizer = TfidfVectorizer(max_features=50000, stop_words='english', ngram_range=(1, 2))\n","\n","X_train = vectorizer.fit_transform(X_train_text)\n","X_test = vectorizer.transform(X_test_text)\n","\n","# 6. TRAIN SVM (LinearSVC)\n","print(\"üöÄ Training SVM (LinearSVC)...\")\n","\n","# D√πng LinearSVC cho t·ªëc ƒë·ªô v√† hi·ªáu su·∫•t cao tr√™n text\n","# class_weight='balanced' r·∫•t quan tr·ªçng v·ªõi FakeNewsNet\n","svm_model = LinearSVC(class_weight='balanced', random_state=42, max_iter=2000)\n","\n","# B·ªçc trong CalibratedClassifierCV ƒë·ªÉ t√≠nh ƒë∆∞·ª£c AUC\n","clf = CalibratedClassifierCV(svm_model)\n","clf.fit(X_train, y_train)\n","\n","# =====================================================\n","# 7. EVALUATION\n","# =====================================================\n","print(\"\\nüéØ ƒêANG ƒê√ÅNH GI√Å (TEST SET)...\")\n","\n","start_time = time.time()\n","\n","y_pred = clf.predict(X_test)\n","y_prob = clf.predict_proba(X_test)[:, 1]\n","\n","end_time = time.time()\n","runtime = end_time - start_time\n","samples_per_second = len(y_test) / runtime\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n","auc = roc_auc_score(y_test, y_prob)\n","\n","eval_results = {\n","    'eval_accuracy': accuracy,\n","    'eval_precision': precision,\n","    'eval_recall': recall,\n","    'eval_f1': f1,\n","    'eval_auc': auc,\n","    'eval_loss': 'N/A (SVM)',\n","    'eval_runtime': runtime,\n","    'eval_samples_per_second': samples_per_second,\n","    'eval_steps_per_second': 'N/A'\n","}\n","\n","print(\"\\n\" + \"=\"*50)\n","print(\"üìä K·∫æT QU·∫¢ SVM BASELINE - FAKENEWSNET:\")\n","print(\"=\"*50)\n","print(eval_results)\n","print(\"=\"*50)\n","\n","# 8. SAVE\n","with open(os.path.join(OUTPUT_DIR, \"svm_fnn_model.pkl\"), \"wb\") as f:\n","    pickle.dump(clf, f)\n","with open(os.path.join(OUTPUT_DIR, \"tfidf_fnn_vectorizer.pkl\"), \"wb\") as f:\n","    pickle.dump(vectorizer, f)\n","print(f\"\\n‚úÖ ƒê√£ l∆∞u model t·∫°i: {OUTPUT_DIR}\")"]}]}